{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "cbbddb9ed9b5e83d0f3ac9c843bcac6843e969899fdd29e0609425a2a7203dd9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_iter,test_iter=d2dl.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "source": [
    "# 定义模型参数\n",
    "num_inputs,num_outputs,num_hiddens=784,10,256\n",
    "W1=torch.tensor(np.random.normal(0,0.01,(num_inputs,num_hiddens)),dtype=torch.float)\n",
    "b1=torch.zeros(num_hiddens,dtype=torch.float)\n",
    "W2=torch.tensor(np.random.normal(0,0.01,(num_hiddens,num_outputs)),dtype=torch.float)\n",
    "b2=torch.zeros(num_outputs,dtype=torch.float)\n",
    "\n",
    "params=[W1,b1,W2,b2]\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义激活函数\n",
    "def relu(X):\n",
    "    return torch.max(input=X,other=torch.tensor(0.0))\n",
    "# 定义模型\n",
    "def net(X):\n",
    "    X=X.view((-1,num_inputs))\n",
    "    H=relu(torch.matmul(X,W1)+b1)\n",
    "    return torch.matmul(H,W2)+b2\n",
    "\n",
    "# 定义损失函数\n",
    "# 为了获得更好的数值稳定性，直接使用PyTorch提供的包括softmax运算和交叉上损失计算的函数\n",
    "loss=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1, loss 0.0090, train acc 0.149, test acc 0.144\n",
      "epoch 2, loss 0.0090, train acc 0.149, test acc 0.144\n",
      "epoch 3, loss 0.0090, train acc 0.149, test acc 0.144\n",
      "epoch 4, loss 0.0090, train acc 0.149, test acc 0.144\n",
      "epoch 5, loss 0.0090, train acc 0.149, test acc 0.144\n"
     ]
    }
   ],
   "source": [
    "num_epochs,lr=5,1.0\n",
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n\n",
    "\n",
    "def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n=0.0,0.0,0\n",
    "        for X,y in train_iter:\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y).sum()\n",
    "\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                torch.optim.SGD(params,lr,batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "            train_l_sum+=l.item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().item()\n",
    "            n+=y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}